{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "#from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt # imshow might be faster?\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "# Load the EMNIST dataset with the correct transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "original_dataset_EMNIST = torchvision.datasets.EMNIST(\n",
    "    root='./data', \n",
    "    split='balanced', \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "balanced_dict = {0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9', 10: 'A', 11: 'B', 12: 'C', 13: 'D', 14: 'E', 15: 'F', 16: \n",
    "                 'G', 17: 'H', 18: 'I', 19: 'J', 20: 'K', 21: 'L', 22: 'M', 23: 'N', 24: 'O', 25: 'P', 26: 'Q', 27: 'R', 28: 'S', 29: 'T', 30: 'U', 31: 'V', \n",
    "                 32: 'W', 33: 'X', 34: 'Y', 35: 'Z', 36: 'a', 37: 'b', 38: 'd', 39: 'e', 40: 'f', 41: 'g', 42: 'h', 43: 'n', 44: 'q', 45: 'r', 46: 't'}\n",
    "\n",
    "def visualize_emnist_samples(dataset):\n",
    "    num_classes = 47  # EMNIST balanced has 47 classes\n",
    "    fig, axes = plt.subplots(7, 7, figsize=(14, 14))\n",
    "    fig.suptitle('EMNIST - One Sample per Class')\n",
    "\n",
    "    class_samples = {}\n",
    "    \n",
    "    # First pass: collect one sample per class\n",
    "    for idx in range(int(len(dataset)/2),len(dataset)):\n",
    "        image, label = dataset[idx]\n",
    "        if label not in class_samples:\n",
    "            class_samples[label] = image\n",
    "            if len(class_samples) == num_classes:\n",
    "                break\n",
    "\n",
    "    # Plot the samples in class order\n",
    "    for label in range(num_classes):\n",
    "        row = label // 7\n",
    "        col = label % 7\n",
    "        ax = axes[row, col]\n",
    "        \n",
    "        # Rotate the image 90 degrees counterclockwise\n",
    "        rotated_image = torch.rot90(class_samples[label], k=-1, dims=[1, 2])\n",
    "        flipped_image = torch.flip(rotated_image, dims=[2])\n",
    "        \n",
    "        ax.imshow(flipped_image.squeeze(), cmap='gray')\n",
    "        ax.set_title(f'Label: {balanced_dict[label]}')\n",
    "        ax.axis('off')\n",
    "\n",
    "    # Remove empty subplots\n",
    "    for i in range(num_classes, 49):\n",
    "        row = i // 7\n",
    "        col = i % 7\n",
    "        fig.delaxes(axes[row, col])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# Visualize one sample per class\n",
    "visualize_emnist_samples(original_dataset_EMNIST)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
