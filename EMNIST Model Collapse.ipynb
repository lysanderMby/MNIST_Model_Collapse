{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstrating model collapse using the balanced EMNIST dataset.\n",
    "\n",
    "Has a very similar structure to the corresponding MNIST scripts. Variational Auto-Encoders (VAEs) are trained on the dataset alongside a classifier. The VAE then has a full 112800 samples drawn (equal to the number in the original balanced EMNIST dataset), which the previously trained classifier then classifies. \n",
    "\n",
    "Model collapse is visible by viewing random samples of the outputs of each iteration of VAE. Note that it is not necessarily possible to draw a balanced sample, as after a certain amount of time variance within the outputs shrinks so much that many of the original classes are no longer represented in the generated datasets. \n",
    "\n",
    "The primary metric of model collapse used is the performance on old trained classifiers on the newly generated data. This is intended to be a data-driven description of how many original features remain, although it also incorporates (unwanted?) information about whether later classifiers identified relevant features, or are using an entirely different scheme. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package Imports\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining parameters\n",
    "\n",
    "# Define hyperparameters # As of right now, these are broadly speaking the same parameters as used in the MNIST trial\n",
    "batch_size = 128\n",
    "latent_dim = 50 # the smallest layer in the VAE\n",
    "vae_hidden_layers = [256, 128, 64] # note that the VAE is symmetric in the encoder and decoder\n",
    "classifier_hidden_dim = 512 # hidden dimension in the classifier\n",
    "learning_rate = 5e-4 \n",
    "vae_num_epochs = 70 \n",
    "classifier_num_epochs = 200 \n",
    "num_iterations = 25  # Number of times to repeat the process\n",
    "num_samples = 112800  # Number of samples to generate in each iteration # Note that original EMNIST (all 112800) are still used regardless of this value for the first iteration\n",
    "num_images = 20 # For printing samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://biometrics.nist.gov/cs_links/EMNIST/gzip.zip to ./data\\EMNIST\\raw\\gzip.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562M/562M [04:09<00:00, 2.25MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\EMNIST\\raw\\gzip.zip to ./data\\EMNIST\\raw\n"
     ]
    }
   ],
   "source": [
    "# Load the balanced EMINST dataset and normalise for faster model convergence\n",
    "\n",
    "# Calculated using 'EMNIST Calculate Statistics.ipynb' \n",
    "dataset_mean = 0.1751\n",
    "dataset_std = 0.3332\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((dataset_mean,), (dataset_std,)) # mean and variance. See later cells to see how these were calculated\n",
    "    # normalisation accelerates convergence of the VAE, and possibly of the classifier. However, it means MSE as opposed to BCE must be used\n",
    "])\n",
    "\n",
    "original_dataset = torchvision.datasets.EMNIST(root='./data', split='balanced', train=True, download=True, transform=transform) # separate download each time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the VAE used. Uses a standard architecture\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_layers, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        encoder_layers = []\n",
    "        prev_dim = input_dim\n",
    "        for hidden_dim in hidden_layers:\n",
    "            encoder_layers.extend([\n",
    "                nn.Linear(prev_dim, hidden_dim),\n",
    "                nn.ReLU()\n",
    "            ])\n",
    "            prev_dim = hidden_dim\n",
    "        self.encoder = nn.Sequential(*encoder_layers)\n",
    "        \n",
    "        self.fc_mu = nn.Linear(hidden_layers[-1], latent_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_layers[-1], latent_dim)\n",
    "        \n",
    "        # Decoder\n",
    "        decoder_layers = []\n",
    "        prev_dim = latent_dim\n",
    "        for hidden_dim in reversed(hidden_layers):\n",
    "            decoder_layers.extend([\n",
    "                nn.Linear(prev_dim, hidden_dim),\n",
    "                nn.ReLU()\n",
    "            ])\n",
    "            prev_dim = hidden_dim\n",
    "        decoder_layers.append(nn.Linear(hidden_layers[0], input_dim))\n",
    "        self.decoder = nn.Sequential(*decoder_layers)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        return self.fc_mu(h), self.fc_logvar(h)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, 784))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the classifier\n",
    "# Note that the classifier loss is given as cross entropy. Defined in the classifier train loop train_classifier\n",
    "\n",
    "# Uses a fully connected linear architecutre. Performance is adequate in earlier iterations\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_classes):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom loss function for the VAE\n",
    "\n",
    "def vae_loss_function(recon_x, x, mu, logvar): # recon_x is short for reconstructed\n",
    "    MSE = nn.functional.mse_loss(recon_x, x.view(-1, 784), reduction='sum') # MSE required. BCE can be used if normalisation is not introduced\n",
    "    # BCE makes more theoretical sense, but seems irrelevant in practice\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) # closed form for KLD between gaussians\n",
    "    return MSE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE main training loop\n",
    "\n",
    "def train_vae(vae, optimizer, dataloader):\n",
    "    vae.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = vae(data) # reconstructed batch straight from vae.forward\n",
    "        loss = vae_loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward() # fails when reparameterisation isn't implemented appropriately\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "    return train_loss / len(dataloader.dataset) # necessary for stability if num_samples is not equal to 60,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier main training loop\n",
    "\n",
    "def train_classifier(classifier, optimizer, dataloader):\n",
    "    classifier.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        output = classifier(data.view(data.size(0), -1))\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    return train_loss / len(dataloader.dataset), correct / len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise loss and accuracy matrices of various classifiers\n",
    "\n",
    "# Visualize the loss and accuracy matrices\n",
    "def plot_matrix(matrix, title, cmap='viridis'): # I have decided I have viridis\n",
    "    plt.figure(figsize=(15, 12)) # made larger than previous versions. To help with readability of text\n",
    "    plt.imshow(matrix, cmap=cmap)\n",
    "    plt.colorbar() # considerably better visualisation\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Dataset Iteration')\n",
    "    plt.ylabel('Classifier Iteration')\n",
    "    for i in range(matrix.shape[0]): # NOTE: Currently counts from 0. I should probably shift it to counting from 1, like all humans do\n",
    "        for j in range(matrix.shape[1]):\n",
    "            plt.text(j, i, f'{matrix[i, j]:.2f}', ha='center', va='center', color='white')\n",
    "    #plt.tight_layout() # produces graphical bugs with the title, but is clearer with the colourbar and labels\n",
    "    plt.show()\n",
    "\n",
    "# Visualise the loss and accuracy matrices without text. Just colour plots\n",
    "def colour_plot_matrix(matrix, title, cmap='viridis', num_ticks=11):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(matrix, cmap=cmap)\n",
    "    plt.colorbar()\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Dataset Iteration')\n",
    "    plt.ylabel('Classifier Iteration')\n",
    "    \n",
    "    # Create evenly spaced tick locations\n",
    "    x_ticks = np.linspace(0, matrix.shape[1] - 1, num_ticks, dtype=int)\n",
    "    y_ticks = np.linspace(0, matrix.shape[0] - 1, num_ticks, dtype=int)\n",
    "    \n",
    "    # Set tick locations and labels\n",
    "    plt.xticks(x_ticks, x_ticks + 1)  # +1 to start from 1 instead of 0\n",
    "    plt.yticks(y_ticks, y_ticks + 1)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create, classify, and display digits\n",
    "\n",
    "def generate_digits(vae, num_samples):\n",
    "    vae.eval()\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(num_samples, latent_dim)\n",
    "        samples = vae.decode(z)\n",
    "    return samples\n",
    "\n",
    "# Classify generated digits. Uses the previous iteration's classifier, bootstrapping future classifiers.\n",
    "# Note that this could potentially be done by directly partitioning the latent space while samples are drawn\n",
    "def classify_digits(classifier, digits):\n",
    "    classifier.eval()\n",
    "    with torch.no_grad():\n",
    "        output = classifier(digits)\n",
    "        labels = output.argmax(dim=1)\n",
    "    return labels\n",
    "\n",
    "def visualize_digits(digits, labels, iteration): # removed the original EMINST code and replaced it with MNIST work. Should work fine?\n",
    "    num_digits = len(digits)\n",
    "    num_rows = math.ceil(num_digits / 10) # required  to allow arbitrary numbers to be shown\n",
    "    # Currently creates a single image out of all of them with 10 columns, and the digits stacked on top of one another\n",
    "    num_cols = min(num_digits, 10)\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(2*num_cols, 2*num_rows))\n",
    "    fig.suptitle(f'Generated Digits - Iteration {iteration}')\n",
    "\n",
    "    balanced_dict = {0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9', 10: 'A', 11: 'B', 12: 'C', 13: 'D', 14: 'E', 15: 'F', 16: \n",
    "                 'G', 17: 'H', 18: 'I', 19: 'J', 20: 'K', 21: 'L', 22: 'M', 23: 'N', 24: 'O', 25: 'P', 26: 'Q', 27: 'R', 28: 'S', 29: 'T', 30: 'U', 31: 'V', \n",
    "                 32: 'W', 33: 'X', 34: 'Y', 35: 'Z', 36: 'a', 37: 'b', 38: 'd', 39: 'e', 40: 'f', 41: 'g', 42: 'h', 43: 'n', 44: 'q', 45: 'r', 46: 't'}\n",
    "\n",
    "    if num_rows == 1:\n",
    "        axes = axes.reshape(1, -1) # avoid index errors\n",
    "\n",
    "    for i in range(num_digits):\n",
    "        row = i // 10\n",
    "        col = i % 10\n",
    "        ax = axes[row, col]\n",
    "        image = digits[i].reshape(28, 28)\n",
    "        rotated_image = torch.rot90(image, k=-1)\n",
    "        flipped_image = torch.flip(rotated_image, dims=[1])\n",
    "        ax.imshow(flipped_image.squeeze(), cmap='gray') # recreates original MNIST images as faithfully as possible. Perhaps a custom cmap would be better for historic accuracy?\n",
    "        ax.set_title(f'Label: {balanced_dict[labels[i].item()]}') # NOTE: Printed images are not sorted by label in any way. This could be resolved in future?\n",
    "        ax.axis('off')\n",
    "\n",
    "    # Remove any unused subplots. Without this, there may be graphical glitches and poorly placed images\n",
    "    for i in range(num_digits, num_rows * num_cols):\n",
    "        row = i // 10\n",
    "        col = i % 10\n",
    "        fig.delaxes(axes[row, col])\n",
    "\n",
    "    plt.tight_layout() # I might want this. It seems to place the title too low, such that it overlaps with the images themselves. Removing this fixes the title issue\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate a given classifier on a given dataset\n",
    "# Returns the cross entropy loss and the accuracy over the whole dataset\n",
    "\n",
    "def evaluate_classifier(classifier, dataloader):\n",
    "    classifier.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in dataloader:\n",
    "            data = data.view(-1, 1, 28, 28)  # Reshape to (batch_size, channels, height, width)\n",
    "            output = classifier(data)\n",
    "            loss = criterion(output, target)\n",
    "            total_loss += loss.item() * data.size(0)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            total += target.size(0)\n",
    "    avg_loss = total_loss / total\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/25\n",
      "VAE Epoch 10/70, Loss: 169.1161\n"
     ]
    }
   ],
   "source": [
    "# Main loop. Iterates over training of models and generating samples for new models\n",
    "current_dataset = original_dataset\n",
    "classifiers = []\n",
    "loss_matrix = np.zeros((num_iterations, num_iterations)) # numpy shortcut for square zeros?\n",
    "accuracy_matrix = np.zeros((num_iterations, num_iterations))\n",
    "\n",
    "vae = VAE(784, vae_hidden_layers, latent_dim) # VAE is not reset after each iteration to save on computational time, requiring fewer generations to keep sensible results\n",
    "for iteration in range(num_iterations):\n",
    "    print(f\"Iteration {iteration + 1}/{num_iterations}\")\n",
    "\n",
    "    # Create DataLoader\n",
    "    dataloader = DataLoader(current_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Initialize and train VAE\n",
    "    #vae = VAE(784, vae_hidden_dim, latent_dim) # currently not being reinitialised\n",
    "    vae_optimizer = optim.Adam(vae.parameters(), lr=learning_rate)\n",
    "    for epoch in range(vae_num_epochs):\n",
    "        loss = train_vae(vae, vae_optimizer, dataloader)\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'VAE Epoch {epoch+1}/{vae_num_epochs}, Loss: {loss:.4f}')\n",
    "\n",
    "    # Initialize and train classifier\n",
    "    classifier = Classifier(784, classifier_hidden_dim, 47) # EMNIST has 47 classes\n",
    "    classifier_optimizer = optim.Adam(classifier.parameters(), lr=learning_rate) # does this need to be respecified?\n",
    "    for epoch in range(classifier_num_epochs):\n",
    "        loss, accuracy = train_classifier(classifier, classifier_optimizer, dataloader)\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Classifier Epoch {epoch+1}/{classifier_num_epochs}, Loss: {loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "\n",
    "    # Store the trained classifier in classifiers list. Used later for overall evaluation\n",
    "    classifiers.append(classifier)\n",
    "\n",
    "    # Generate new dataset\n",
    "    generated_digits = generate_digits(vae, num_samples)\n",
    "    generated_labels = classify_digits(classifier, generated_digits) # from prev classifier notably\n",
    "\n",
    "    # Visualize some generated digits\n",
    "    #visualize_digits(generated_digits[:num_images*num_cols], generated_labels[:num_images*num_cols], iteration + 1, num_rows=num_images, num_cols=num_cols) # num_images used to be set to 25. Produces no issues\n",
    "    visualize_digits(generated_digits[:num_images], generated_labels[:num_images], iteration + 1) # num_images used to be set to 25. Produces no issues\n",
    "\n",
    "\n",
    "    # Create new dataset for next iteration\n",
    "    current_dataset = TensorDataset(generated_digits, generated_labels) # torch.utils.data.TensorDataset\n",
    "\n",
    "    # Evaluate all previous classifiers on the new dataset, and writing to the loss and accuracy arrays\n",
    "    new_dataloader = DataLoader(current_dataset, batch_size=batch_size, shuffle=False) # shuffle should be unnecessary as the sampling from the latent space is random\n",
    "    for prev_iteration, prev_classifier in enumerate(classifiers):\n",
    "        loss, accuracy = evaluate_classifier(prev_classifier, new_dataloader)\n",
    "        loss_matrix[prev_iteration, iteration] = loss\n",
    "        accuracy_matrix[prev_iteration, iteration] = accuracy\n",
    "\n",
    "    # This line can be used to save the current dataset for later analysis. Requires drive loading\n",
    "    #torch.save(current_dataset, f'generated_dataset_iteration_{iteration + 1}.pt')\n",
    "\n",
    "# Save matrices for further analysis\n",
    "#np.save('loss_matrix_EMNIST.npy', loss_matrix)\n",
    "#np.save('accuracy_matrix_EMNIST.npy', accuracy_matrix)\n",
    "\n",
    "# Display the relevative accuracies of trained classifiers\n",
    "\n",
    "plot_matrix(loss_matrix, 'Loss Matrix')\n",
    "plot_matrix(accuracy_matrix, 'Accuracy Matrix')\n",
    "\n",
    "colour_plot_matrix(loss_matrix, 'Loss Matrix')\n",
    "colour_plot_matrix(accuracy_matrix, 'Accuracy Matrix')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
